{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "supreme-hurricane",
   "metadata": {},
   "source": [
    "#### Submitted By: Lior Kricheli, Eliran Malka and Itamar Yacoby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "referenced-athletics",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install patchify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hollywood-transport",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Input, Conv2D, MaxPooling2D, GlobalAveragePooling2D, GlobalMaxPooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import cv2\n",
    "import tifffile as tiff\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from seaborn import heatmap \n",
    "from sklearn.manifold import TSNE\n",
    "from patchify import patchify\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "equipped-voltage",
   "metadata": {},
   "source": [
    "# IMPORTANT!\n",
    "## Choose bellow the right cell to run (Colab or PC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "preliminary-treaty",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #USE THIS CELL TO RUN ON COLAB\n",
    "\n",
    "# !git clone https://github.com/ithamar000/DeepLearningFinalProject.git\n",
    "\n",
    "# pathTrain = '/content/DeepLearningFinalProject/archive/Kather_texture_2016_image_tiles_5000/Kather_texture_2016_image_tiles_5000/train'\n",
    "# pathTest = '/content/DeepLearningFinalProject/archive/Kather_texture_2016_image_tiles_5000/Kather_texture_2016_image_tiles_5000/validation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "healthy-height",
   "metadata": {},
   "outputs": [],
   "source": [
    "#USE THIS CELL TO RUN ON PC\n",
    "\n",
    "pathTrain = 'archive\\\\Kather_texture_2016_image_tiles_5000\\\\Kather_texture_2016_image_tiles_5000\\\\train'\n",
    "pathTest = 'archive\\\\Kather_texture_2016_image_tiles_5000\\\\Kather_texture_2016_image_tiles_5000\\\\validation'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "drawn-death",
   "metadata": {},
   "source": [
    "# Part 1: Function Defenitions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incident-aurora",
   "metadata": {},
   "source": [
    "#### plot_results(history)\n",
    "\n",
    "plot the accuracy and loss.\n",
    "\n",
    "##### history - contains the accuracy and loss of a trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "laughing-default",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(history):\n",
    "    plt.figure(figsize=(12,4))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(history.history['loss'],':r')\n",
    "    plt.plot(history.history['val_loss'],'.-r')\n",
    "    plt.title('Loss',fontsize=14)\n",
    "    plt.xlabel('Epochs',fontsize=14)\n",
    "    plt.grid()\n",
    "\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(history.history['accuracy'],':b')\n",
    "    plt.plot(history.history['val_accuracy'],'b')\n",
    "    plt.ylim([0, 1])\n",
    "    plt.title('Accuracy',fontsize=14)\n",
    "    plt.xlabel('Epochs',fontsize=14)\n",
    "    plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deluxe-picking",
   "metadata": {},
   "source": [
    "#### plot_confusion_matrix(model, test_generator)\n",
    "plot a confusion matrix\n",
    "\n",
    "##### model - The trained model\n",
    "##### test_generator - the generator used by the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spanish-rwanda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot a confusion matrix\n",
    "\n",
    "def plot_confusion_matrix(model, test_generator):\n",
    "    true_labels = test_generator.classes\n",
    "    predictions = model.predict(test_generator)\n",
    "    y_true = true_labels\n",
    "    y_pred = np.array([np.argmax(x) for x in predictions])\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    CM = cm / cm.sum(axis=1)\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(10,8))\n",
    "    heatmap(CM,cmap='Blues',annot=True, fmt='.2%')\n",
    "    plt.xlabel('Predicted label', fontsize=20)\n",
    "    plt.ylabel('True label', fontsize=20)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "anticipated-nudist",
   "metadata": {},
   "source": [
    "#### visualize_labelled_data(model, test_generator)\n",
    "\n",
    "Function to plot a visualization of labelled-data distribution in 2D (Using t-SNE) \n",
    "\n",
    "##### model - The trained model\n",
    "##### test_generator - the generator used by the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "varying-graphics",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot a visualization of labelled-data distribution in 2D (Using t-SNE) \n",
    "\n",
    "def visualize_labelled_data(model, test_generator):\n",
    "    features_extractor = keras.Model(inputs=model.inputs, outputs=model.layers[-2].output)\n",
    "    features = features_extractor.predict(test_generator)\n",
    "\n",
    "    X_embedded = TSNE(n_components=2).fit_transform(features)\n",
    "    y = test_generator.classes\n",
    "\n",
    "    plt.figure(figsize=(10,8))\n",
    "    plt.scatter(X_embedded[:,0],X_embedded[:,1],80,y, \n",
    "                cmap='tab20', alpha=0.7, edgecolors='k')\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liquid-bhutan",
   "metadata": {},
   "source": [
    "#### get_data_gen(data_augmentation)\n",
    "\n",
    "Returns data generator\n",
    "\n",
    "if data_augmentation == True -> applying data augmentation to images\n",
    "\n",
    "else the images remains in their original condition\n",
    "\n",
    "##### data_augmentation - boolean to decide if data augmentation is wanted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beautiful-provincial",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_data_gen(data_augmentation):\n",
    "    \n",
    "    my_batch_size = 32  \n",
    "    \n",
    "    if(data_augmentation):\n",
    "        dataGen = ImageDataGenerator(shear_range=0.2,\n",
    "                                     zoom_range=0.2,\n",
    "                                     horizontal_flip=True,\n",
    "                                     rotation_range=30,\n",
    "                                     width_shift_range=2,)\n",
    "        \n",
    "        train_generator = dataGen.flow_from_directory(pathTrain,\n",
    "                                                      batch_size=my_batch_size, \n",
    "                                                      class_mode='categorical')\n",
    "\n",
    "        dataGenTest = ImageDataGenerator()\n",
    "        test_generator = dataGenTest.flow_from_directory(pathTest,                                              \n",
    "                                                     batch_size=my_batch_size, \n",
    "                                                     class_mode='categorical', \n",
    "                                                     shuffle=False)\n",
    "    else:\n",
    "        dataGen = ImageDataGenerator()\n",
    "        train_generator = dataGen.flow_from_directory(pathTrain,\n",
    "                                                      batch_size=my_batch_size, \n",
    "                                                      class_mode='categorical')\n",
    "\n",
    "        dataGenTest = ImageDataGenerator()\n",
    "        test_generator = dataGenTest.flow_from_directory(pathTest,                                              \n",
    "                                                     batch_size=my_batch_size, \n",
    "                                                     class_mode='categorical', \n",
    "                                                     shuffle=False)\n",
    "    return train_generator,test_generator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lasting-branch",
   "metadata": {},
   "source": [
    "#### get_big_model()\n",
    "\n",
    "Returns a ConvNet Model containing mulitple Conv Layers, Dropout, and Max Pooling\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "similar-replica",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_big_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters = 16, kernel_size = 3, padding = 'same', activation = 'relu', input_shape = (150, 150, 3)))\n",
    "    model.add(Conv2D(filters = 16, kernel_size = 3, padding = 'same', activation = 'relu'))\n",
    "    model.add(Conv2D(filters = 16, kernel_size = 3, padding = 'same', activation = 'relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(MaxPooling2D(pool_size = 3)) \n",
    "\n",
    "    model.add(Conv2D(filters = 32, kernel_size = 3, padding = 'same', activation = 'relu')) \n",
    "    model.add(Conv2D(filters = 32, kernel_size = 3, padding = 'same', activation = 'relu')) \n",
    "    model.add(Conv2D(filters = 32, kernel_size = 3, padding = 'same', activation = 'relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(MaxPooling2D(pool_size = 3)) \n",
    "\n",
    "    model.add(Conv2D(filters = 64, kernel_size = 3, padding = 'same', activation = 'relu'))\n",
    "    model.add(Conv2D(filters = 64, kernel_size = 3, padding = 'same', activation = 'relu'))\n",
    "    model.add(Conv2D(filters = 64, kernel_size = 3, padding = 'same', activation = 'relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(MaxPooling2D(pool_size = 3))\n",
    "\n",
    "    model.add(Conv2D(filters = 128, kernel_size = 3, padding = 'same', activation = 'relu'))\n",
    "    model.add(Conv2D(filters = 128, kernel_size = 3, padding = 'same', activation = 'relu'))\n",
    "    model.add(Conv2D(filters = 256, kernel_size = 3, padding = 'same', activation = 'relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(MaxPooling2D(pool_size = 3))\n",
    "    model.add(GlobalMaxPooling2D())\n",
    "    model.add(Dense(8, activation = 'softmax'))\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inclusive-assumption",
   "metadata": {},
   "source": [
    "#### get_small_model()\n",
    "\n",
    "Returns a small ConvNet model containing some Conv Layers and Max Pooling without Dropout\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alike-shaft",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_small_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters = 16, kernel_size = 3, padding = 'same', activation = 'relu', input_shape = (150, 150, 3)))\n",
    "    model.add(MaxPooling2D(pool_size = 3)) \n",
    "    model.add(Conv2D(filters = 32, kernel_size = 3, padding = 'same', activation = 'relu')) \n",
    "    model.add(MaxPooling2D(pool_size = 3)) \n",
    "    model.add(Conv2D(filters = 64, kernel_size = 3, padding = 'same', activation = 'relu'))\n",
    "    model.add(MaxPooling2D(pool_size = 3))\n",
    "    model.add(GlobalMaxPooling2D())\n",
    "    model.add(Dense(8, activation = 'softmax'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "internal-yorkshire",
   "metadata": {},
   "source": [
    "# Part 2: Training Multiple Models\n",
    "\n",
    "#### In this part we will train three different model with different complexity\n",
    "#### In the table below you can see the results we achieved with each model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "flying-jerusalem",
   "metadata": {},
   "source": [
    "## Summary of results:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vanilla-lucas",
   "metadata": {},
   "source": [
    "<table>\n",
    "  <tr>\n",
    "    <th>Model</th>\n",
    "    <th>#parameters</th>\n",
    "    <th>epochs</th>\n",
    "    <th>train accuracy</th>\n",
    "    <th>test accuracy</th>\n",
    "  </tr>\n",
    "    \n",
    "  <!-- copy this block once for every model you tested -->  \n",
    "  <tr> \n",
    "    <td>> Simple ConvNet </td>   <!-- Model -->\n",
    "    <td>> 0 </td> <!-- Parameters -->\n",
    "    <td>> 10 </td> <!-- epochs -->\n",
    "    <td>> 0.0 </td> <!-- train -->\n",
    "    <td>> 0.0 </td> <!--  test -->\n",
    "  </tr>\n",
    "\n",
    "  <tr> \n",
    "    <td>> Simple ConvNet Data Augmentation</td>   <!-- model -->\n",
    "    <td>> 0 </td> <!-- parameters -->\n",
    "    <td>> 20 </td> <!-- epochs -->\n",
    "    <td>> 0.0</td> <!-- train -->\n",
    "    <td>> 0.0 </td> <!-- test -->\n",
    "  </tr>\n",
    "\n",
    "  <tr> \n",
    "    <td>> Bigger ConvNet Data Augmentation + Adam optimizer</td>   <!-- model -->\n",
    "    <td>> 0 </td> <!-- parameters -->\n",
    "    <td>> 30 </td> <!-- epochs -->\n",
    "    <td>> 0.0</td> <!-- train -->\n",
    "    <td>> 0.0 </td> <!-- test -->\n",
    "  </tr>\n",
    "    \n",
    "</table>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "korean-horror",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initializing  two sets of data generator, one with augmentaion and one without.\n",
    "\n",
    "train_generator_original ,test_generator_original = get_data_gen(False)\n",
    "train_generator_aug, test_generator_aug = get_data_gen(True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fluid-serum",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_model = get_small_model()\n",
    "small_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "declared-grenada",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "epochs = 1\n",
    "\n",
    "small_model_history = small_model.fit(train_generator_original,\n",
    "                                      steps_per_epoch=train_generator_original.samples/train_generator_original.batch_size, \n",
    "                                      validation_data=test_generator_original,\n",
    "                                      epochs=epochs, batch_size=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unable-notification",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(small_model_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "literary-glory",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_model_aug = get_small_model()\n",
    "small_model_aug.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "epochs = 20\n",
    "\n",
    "small_model_aug_history = small_model_aug.fit(train_generator_aug,\n",
    "                                      steps_per_epoch=train_generator_aug.samples/train_generator_aug.batch_size, \n",
    "                                      validation_data=test_generator_aug,\n",
    "                                      epochs=epochs, batch_size=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fantastic-retrieval",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(small_model_aug_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amended-stevens",
   "metadata": {},
   "outputs": [],
   "source": [
    "big_model = get_big_model()\n",
    "big_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modified-language",
   "metadata": {},
   "outputs": [],
   "source": [
    "big_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "epochs = 30\n",
    "\n",
    "big_model_history = big_model.fit(train_generator_aug, steps_per_epoch=train_generator_aug.samples/train_generator_aug.batch_size, \n",
    "          validation_data=test_generator_aug,\n",
    "          epochs=epochs, batch_size=20, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expanded-gates",
   "metadata": {},
   "source": [
    "# Part 2.1: Visualizing the results of our best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "soviet-quantity",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(big_model_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cultural-metabolism",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(big_model,test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "terminal-austria",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_labelled_data(big_model, test_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "colored-anthony",
   "metadata": {},
   "source": [
    "# Part 3: Image Segmentation\n",
    "\n",
    "#### In this part we will use the trained model to classify small patches of a large image to help detect tumors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ultimate-header",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rough-celtic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# largeImagesPath = ''\n",
    "\n",
    "# image = tiff.imread('archive\\Kather_texture_2016_larger_images_10\\Kather_texture_2016_larger_images_10\\CRC-Prim-HE-01_APPLICATION.tif')\n",
    "# #img = img_to_array(image)\n",
    "# #img = image[:,:,0]\n",
    "\n",
    "# patches = patchify(image, (150, 150, 3), step=15)\n",
    "# patchesRe = np.reshape(patches,(-1,150,150,3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "normal-miniature",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for i in range(patches.shape[0]):\n",
    "# #         for j in range(patches.shape[1]):\n",
    "# #             single_patch = patches[i,j,:,:]\n",
    "# #             cv2.imwrite('image.tif',single_patch)\n",
    "\n",
    "# cv2.imwrite('image.tif',patches[0,0,0,:,:])            \n",
    "# single_patch = patches[0,0,0,:,:]\n",
    "# test = cv2.imread('archive\\\\Kather_texture_2016_image_tiles_5000\\\\Kather_texture_2016_image_tiles_5000\\\\train\\\\01_TUMOR\\\\1BAF_CRC-Prim-HE-03_009.tif_Row_151_Col_151.tif')\n",
    "# sp = np.reshape(single_patch,(-1,150,150,3))\n",
    "# sp.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "together-great",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.predict(patchesRe[0,0,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "circular-supervision",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testtest = np.reshape(test,(-1,150,150,3))\n",
    "# model.predict(testtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assisted-render",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
